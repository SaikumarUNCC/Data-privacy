{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_nR9GfAYtp_"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow numpy matplotlib opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "E00yTVNsYyeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(image_path, size=(64,64)):\n",
        "    data = []\n",
        "    for img in os.listdir(image_path):\n",
        "        img_arr = cv2.imread(os.path.join(image_path, img))[...,::-1] # convert BGR to RGB format\n",
        "        resized_arr = cv2.resize(img_arr, size) # Reshape images to preferred size\n",
        "        data.append(resized_arr)\n",
        "    return np.array(data) / 255.0\n",
        "\n",
        "# Assuming you have a folder 'dataset' with all images\n",
        "images = load_images('dataset')\n"
      ],
      "metadata": {
        "id": "yCZhAn3aY3ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(latent_dim):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(128, activation=\"relu\", input_dim=latent_dim),\n",
        "        layers.Reshape((8, 8, 2)),\n",
        "        layers.UpSampling2D(),\n",
        "        layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
        "        layers.UpSampling2D(),\n",
        "        layers.Conv2D(3, kernel_size=3, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator(image_shape):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(64, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "latent_dim = 100\n",
        "discriminator = build_discriminator(images.shape[1:])\n",
        "generator = build_generator(latent_dim)\n",
        "\n",
        "# GAN Model\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "discriminator.trainable = False\n",
        "gan_input = layers.Input(shape=(latent_dim,))\n",
        "fake_image = generator(gan_input)\n",
        "gan_output = discriminator(fake_image)\n",
        "gan = models.Model(gan_input, gan_output)\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')\n"
      ],
      "metadata": {
        "id": "2Nfm7wdAY5hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_gan(generator, discriminator, gan, images, latent_dim, epochs=100, batch_size=128):\n",
        "    for e in range(epochs):\n",
        "        for _ in range(batch_size):\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            generated_images = generator.predict(noise)\n",
        "            real_images = images[np.random.randint(0, images.shape[0], batch_size)]\n",
        "\n",
        "            X = np.concatenate([generated_images, real_images])\n",
        "            y = np.zeros(2*batch_size)\n",
        "            y[:batch_size] = 0.9  # Label smoothing\n",
        "\n",
        "            d_loss = discriminator.train_on_batch(X, y)\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "            y_gen = np.ones(batch_size)\n",
        "            g_loss = gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "        print(f'Epoch {e+1} / {epochs}, Discriminator Loss: {d_loss}, Generator Loss: {g_loss}')\n",
        "\n",
        "train_gan(generator, discriminator, gan, images, latent_dim)\n"
      ],
      "metadata": {
        "id": "MHHopuVlY7Cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(generator, n_images=6):\n",
        "    noise = np.random.normal(0, 1, (n_images, latent_dim))\n",
        "    generated_images = generator.predict(noise)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i in range(n_images):\n",
        "        plt.subplot(2, 3, i+1)\n",
        "        plt.imshow(generated_images[i])\n",
        "        plt.axis('off')\n",
        "    plt\n"
      ],
      "metadata": {
        "id": "N1oAgTSPY8vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
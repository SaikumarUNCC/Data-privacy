{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_nR9GfAYtp_"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow numpy matplotlib opencv-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Main entry point for training StyleGAN and ProGAN networks.\"\"\"\n",
        "\n",
        "import copy\n",
        "import dnnlib\n",
        "from dnnlib import EasyDict\n",
        "\n",
        "import config\n",
        "from metrics import metric_base\n",
        "\n",
        "\n",
        "if 1:\n",
        "    desc          = 'sgan'                                                                 # Description string included in result subdir name.\n",
        "    train         = EasyDict(run_func_name='training.training_loop.training_loop')         # Options for training loop.\n",
        "    G             = EasyDict(func_name='training.networks_stylegan.G_style')               # Options for generator network.\n",
        "    D             = EasyDict(func_name='training.networks_stylegan.D_basic')               # Options for discriminator network.\n",
        "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for generator optimizer.\n",
        "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                          # Options for discriminator optimizer.\n",
        "    G_loss        = EasyDict(func_name='training.loss.G_logistic_nonsaturating')           # Options for generator loss.\n",
        "    D_loss        = EasyDict(func_name='training.loss.D_logistic_simplegp', r1_gamma=10.0) # Options for discriminator loss.\n",
        "    dataset       = EasyDict()                                                             # Options for load_dataset().\n",
        "    sched         = EasyDict()                                                             # Options for TrainingSchedule.\n",
        "    grid          = EasyDict(size='4k', layout='random')                                   # Options for setup_snapshot_image_grid().\n",
        "    metrics       = [metric_base.fid50k]                                                   # Options for MetricGroup.\n",
        "    submit_config = dnnlib.SubmitConfig()                                                  # Options for dnnlib.submit_run().\n",
        "    tf_config     = {'rnd.np_random_seed': 1000}                                           # Options for tflib.init_tf().\n",
        "\n",
        "    # Dataset.\n",
        "    desc += '-ffhq';     dataset = EasyDict(tfrecord_dir='ffhq');                 train.mirror_augment = True\n",
        "    #desc += '-ffhq512';  dataset = EasyDict(tfrecord_dir='ffhq', resolution=512); train.mirror_augment = True\n",
        "    #desc += '-ffhq256';  dataset = EasyDict(tfrecord_dir='ffhq', resolution=256); train.mirror_augment = True\n",
        "    #desc += '-celebahq'; dataset = EasyDict(tfrecord_dir='celebahq');             train.mirror_augment = True\n",
        "    #desc += '-bedroom';  dataset = EasyDict(tfrecord_dir='lsun-bedroom-full');    train.mirror_augment = False\n",
        "    #desc += '-car';      dataset = EasyDict(tfrecord_dir='lsun-car-512x384');     train.mirror_augment = False\n",
        "    #desc += '-cat';      dataset = EasyDict(tfrecord_dir='lsun-cat-full');        train.mirror_augment = False\n",
        "\n",
        "    # Number of GPUs.\n",
        "    #desc += '-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}\n",
        "    #desc += '-2gpu'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}\n",
        "    #desc += '-4gpu'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}\n",
        "    desc += '-8gpu'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}\n",
        "\n",
        "    # Default options.\n",
        "    train.total_kimg = 25000\n",
        "    sched.lod_initial_resolution = 8\n",
        "    sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
        "    sched.D_lrate_dict = EasyDict(sched.G_lrate_dict)\n",
        "\n",
        "\n",
        "\n",
        "if 0:\n",
        "    desc          = 'pgan'                                                         # Description string included in result subdir name.\n",
        "    train         = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n",
        "    G             = EasyDict(func_name='training.networks_progan.G_paper')         # Options for generator network.\n",
        "    D             = EasyDict(func_name='training.networks_progan.D_paper')         # Options for discriminator network.\n",
        "    G_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n",
        "    D_opt         = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n",
        "    G_loss        = EasyDict(func_name='training.loss.G_wgan')                     # Options for generator loss.\n",
        "    D_loss        = EasyDict(func_name='training.loss.D_wgan_gp')                  # Options for discriminator loss.\n",
        "    dataset       = EasyDict()                                                     # Options for load_dataset().\n",
        "    sched         = EasyDict()                                                     # Options for TrainingSchedule.\n",
        "    grid          = EasyDict(size='1080p', layout='random')                        # Options for setup_snapshot_image_grid().\n",
        "    metrics       = [metric_base.fid50k]                                           # Options for MetricGroup.\n",
        "    submit_config = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n",
        "    tf_config     = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n",
        "\n",
        "    # Dataset (choose one).\n",
        "    desc += '-celebahq';            dataset = EasyDict(tfrecord_dir='celebahq'); train.mirror_augment = True\n",
        "\n",
        "\n",
        "    # Config presets (choose one).\n",
        "    #desc += '-preset-v1-1gpu'; submit_config.num_gpus = 1; D.mbstd_group_size = 16; sched.minibatch_base = 16; sched.minibatch_dict = {256: 14, 512: 6, 1024: 3}; sched.lod_training_kimg = 800; sched.lod_transition_kimg = 800; train.total_kimg = 19000\n",
        "    desc += '-preset-v2-1gpu'; submit_config.num_gpus = 1; sched.minibatch_base = 4; sched.minibatch_dict = {4: 128, 8: 128, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8, 512: 4}; sched.G_lrate_dict = {1024: 0.0015}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-2gpus'; submit_config.num_gpus = 2; sched.minibatch_base = 8; sched.minibatch_dict = {4: 256, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16, 256: 8}; sched.G_lrate_dict = {512: 0.0015, 1024: 0.002}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-4gpus'; submit_config.num_gpus = 4; sched.minibatch_base = 16; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 16}; sched.G_lrate_dict = {256: 0.0015, 512: 0.002, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "    #desc += '-preset-v2-8gpus'; submit_config.num_gpus = 8; sched.minibatch_base = 32; sched.minibatch_dict = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32}; sched.G_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}; sched.D_lrate_dict = EasyDict(sched.G_lrate_dict); train.total_kimg = 12000\n",
        "\n",
        "    # Numerical precision (choose one).\n",
        "    desc += '-fp32'; sched.max_minibatch_per_gpu = {256: 16, 512: 8, 1024: 4}\n",
        "    #desc += '-fp16'; G.dtype = 'float16'; D.dtype = 'float16'; G.pixelnorm_epsilon=1e-4; G_opt.use_loss_scaling = True; D_opt.use_loss_scaling = True; sched.max_minibatch_per_gpu = {512: 16, 1024: 8}\n",
        "\n",
        "    # Disable individual features.\n",
        "    #desc += '-nogrowing'; sched.lod_initial_resolution = 1024; sched.lod_training_kimg = 0; sched.lod_transition_kimg = 0; train.total_kimg = 10000\n",
        "    #desc += '-nopixelnorm'; G.use_pixelnorm = False\n",
        "    #desc += '-nowscale'; G.use_wscale = False; D.use_wscale = False\n",
        "    #desc += '-noleakyrelu'; G.use_leakyrelu = False\n",
        "    #desc += '-nosmoothing'; train.G_smoothing_kimg = 0.0\n",
        "    #desc += '-norepeat'; train.minibatch_repeats = 1\n",
        "    #desc += '-noreset'; train.reset_opt_for_new_lod = False\n",
        "\n",
        "    # Special modes.\n",
        "    #desc += '-BENCHMARK'; sched.lod_initial_resolution = 4; sched.lod_training_kimg = 3; sched.lod_transition_kimg = 3; train.total_kimg = (8*2+1)*3; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
        "    #desc += '-BENCHMARK0'; sched.lod_initial_resolution = 1024; train.total_kimg = 10; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1000; train.network_snapshot_ticks = 1000\n",
        "    #desc += '-VERBOSE'; sched.tick_kimg_base = 1; sched.tick_kimg_dict = {}; train.image_snapshot_ticks = 1; train.network_snapshot_ticks = 100\n",
        "    #desc += '-GRAPH'; train.save_tf_graph = True\n",
        "    #desc += '-HIST'; train.save_weight_histograms = True\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "# Main entry point for training.\n",
        "# Calls the function indicated by 'train' using the selected options.\n",
        "\n",
        "def main():\n",
        "    kwargs = EasyDict(train)\n",
        "    kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n",
        "    kwargs.update(dataset_args=dataset, sched_args=sched, grid_args=grid, metric_arg_list=metrics, tf_config=tf_config)\n",
        "    kwargs.submit_config = copy.deepcopy(submit_config)\n",
        "    kwargs.submit_config.run_dir_root = dnnlib.submission.submit.get_template_from_path(config.result_dir)\n",
        "    kwargs.submit_config.run_dir_ignore += config.run_dir_ignore\n",
        "    kwargs.submit_config.run_desc = desc\n",
        "    dnnlib.submit_run(**kwargs)\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#----------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "N1oAgTSPY8vu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}